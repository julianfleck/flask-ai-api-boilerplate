"""Initial migration

Revision ID: cd2aecbe125b
Revises: 
Create Date: 2024-11-19 18:58:37.873569

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'cd2aecbe125b'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('api_storage', schema=None) as batch_op:
        batch_op.drop_index('ix_api_storage_endpoint')
        batch_op.drop_index('ix_api_storage_storage_type')
        batch_op.drop_index('ix_api_storage_ttl')
        batch_op.drop_index('ix_api_storage_user_id')

    op.drop_table('api_storage')
    with op.batch_alter_table('api_keys', schema=None) as batch_op:
        batch_op.drop_index('ix_api_keys_key_hash')
        batch_op.drop_index('ix_api_keys_user_id')

    op.drop_table('api_keys')
    with op.batch_alter_table('items', schema=None) as batch_op:
        batch_op.drop_index('ix_items_name')

    op.drop_table('items')
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.drop_index('ix_users_email')

    op.drop_table('users')
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('users',
    sa.Column('id', sa.INTEGER(), server_default=sa.text("nextval('users_id_seq'::regclass)"), autoincrement=True, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('email', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('hashed_password', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('full_name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('role', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('is_active', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('last_login_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('login_count', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('preferences', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('permissions', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='users_pkey'),
    postgresql_ignore_search_path=False
    )
    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.create_index('ix_users_email', ['email'], unique=True)

    op.create_table('items',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('description', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('properties', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name='items_user_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='items_pkey')
    )
    with op.batch_alter_table('items', schema=None) as batch_op:
        batch_op.create_index('ix_items_name', ['name'], unique=False)

    op.create_table('api_keys',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('key_hash', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('last_used_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('expires_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('is_active', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('scopes', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name='api_keys_user_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='api_keys_pkey')
    )
    with op.batch_alter_table('api_keys', schema=None) as batch_op:
        batch_op.create_index('ix_api_keys_user_id', ['user_id'], unique=False)
        batch_op.create_index('ix_api_keys_key_hash', ['key_hash'], unique=False)

    op.create_table('api_storage',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('endpoint', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('ttl', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('compressed', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('storage_metadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('storage_type', postgresql.ENUM('REQUEST', 'RESPONSE', 'BOTH', name='storagetype'), autoincrement=False, nullable=False),
    sa.Column('request_data', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.Column('response_data', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='api_storage_pkey')
    )
    with op.batch_alter_table('api_storage', schema=None) as batch_op:
        batch_op.create_index('ix_api_storage_user_id', ['user_id'], unique=False)
        batch_op.create_index('ix_api_storage_ttl', ['ttl'], unique=False)
        batch_op.create_index('ix_api_storage_storage_type', ['storage_type'], unique=False)
        batch_op.create_index('ix_api_storage_endpoint', ['endpoint'], unique=False)

    # ### end Alembic commands ###
